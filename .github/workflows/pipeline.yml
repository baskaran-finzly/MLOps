name: Wellness Tourism MLOps Pipeline

on:
  workflow_dispatch:  # Allows manual triggering
  push:
    branches:
      - main  # Automatically runs when code is pushed to main branch

jobs:

  register-dataset:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install Dependencies
        run: pip install -r requirements.txt
      - name: Upload Dataset to Hugging Face Hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: python model_building/data_register.py

  data-prep:
    needs: register-dataset
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install Dependencies
        run: pip install -r requirements.txt
      - name: Run Data Preparation
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: python model_building/prep.py

  model-training:
    needs: data-prep
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install Dependencies
        run: pip install -r requirements.txt
      - name: Model Building and Training
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          # MLflow uses file-based tracking by default (./mlruns)
          # To use remote MLflow server, set: MLFLOW_TRACKING_URI
          # MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}  # Optional
        run: python model_building/train.py
      # Optional: Upload MLflow artifacts
      # - name: Upload MLflow Artifacts
      #   uses: actions/upload-artifact@v3
      #   if: always()
      #   with:
      #     name: mlflow-runs
      #     path: mlruns/
      #     retention-days: 30

  deploy-hosting:
    runs-on: ubuntu-latest
    needs: [model-training, data-prep, register-dataset]
    steps:
      - uses: actions/checkout@v3
      - name: Install Dependencies
        run: pip install -r requirements.txt
      - name: Push files to Hugging Face Space
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: python hosting/hosting.py

